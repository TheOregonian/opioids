{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opioid data from ARCOS\n",
    "\n",
    "This notebook takes zipped state files from The Washington Post site, opens them up one by one, and calculates rates of pill sales per pharmacy based on two methodologies. \n",
    "\n",
    "A csv file with population data is included in this repository. To run the notebook, a user should place all zipped ARCOS files in a subdirectory called \"data\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import gzip\n",
    "import os, os.path\n",
    "import shutil\n",
    "pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['AK',\n",
    "'AL',\n",
    "'AR',\n",
    "'AZ',\n",
    "'CO',\n",
    "'CT',\n",
    "'DE',\n",
    "'GA',\n",
    "'HI',\n",
    "'IA',\n",
    "'ID',\n",
    "'IL',\n",
    "'IN',\n",
    "'KS',\n",
    "'KY',\n",
    "'LA',\n",
    "'MA',\n",
    "'MD',\n",
    "'ME',\n",
    "'MI',\n",
    "'MN',\n",
    "'MO',\n",
    "'MS',\n",
    "'MT',\n",
    "'NC',\n",
    "'ND',\n",
    "'NE',\n",
    "'NH',\n",
    "'NJ',\n",
    "'NM',\n",
    "'NV',\n",
    "'NY',\n",
    "'OH',\n",
    "'OK',\n",
    "'OR',\n",
    "'PA',\n",
    "'RI',\n",
    "'SC',\n",
    "'SD',\n",
    "'TN',\n",
    "'UT',\n",
    "'VA',\n",
    "'VT',\n",
    "'WA',\n",
    "'WI',\n",
    "'WV',\n",
    "'WY',\n",
    "'TX',\n",
    "'CA',\n",
    "'FL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_state(state):\n",
    "    # Get the raw data\n",
    "    try:\n",
    "        opioids = pd.read_csv('data/'+state+'/arcos-' + state.lower() + '-statewide-itemized.tsv', sep='\\t', header=0)\n",
    "    except:\n",
    "        opioids = pd.read_csv('data/arcos-' + state.lower() + '-statewide-itemized.tsv', sep='\\t', header=0)\n",
    "\n",
    "    # Isolate pharmacies\n",
    "    pharmacies = opioids[opioids.BUYER_BUS_ACT.str.contains('PHARMACY', na=False)]\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Washington Post analysis\n",
    "    # ---------------------------\n",
    "    \n",
    "    # Calculate sales per store, by county\n",
    "    per_store_by_county = pharmacies.groupby(by=['BUYER_DEA_NO','BUYER_NAME','BUYER_ADDRESS1','BUYER_CITY','BUYER_ZIP','BUYER_COUNTY','BUYER_STATE']).DOSAGE_UNIT.sum().reset_index()\n",
    "\n",
    "    # Get population data and attach it to sales per store by county\n",
    "    population = pd.read_csv('county_pop_20062012.csv')\n",
    "    pos = population.columns.get_loc('variable') + 1\n",
    "    population['Average_population'] = population.iloc[:, pos:].mean(axis=1)\n",
    "    population.county_name = population.county_name.str.upper()\n",
    "    population = population[['BUYER_STATE','BUYER_COUNTY','Average_population']]\n",
    "    per_store_by_county = pd.merge(per_store_by_county,population,on = ['BUYER_STATE','BUYER_COUNTY'],how='left')\n",
    "    \n",
    "    # Calculate pills per total county population per year\n",
    "    per_store_by_county['Rate'] = (per_store_by_county.DOSAGE_UNIT.astype(float)/per_store_by_county.Average_population.astype(float))/7\n",
    "    per_store_by_county.to_csv('all_stores_' + state + '.csv')\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Alternative analysis\n",
    "    # ---------------------------\n",
    "\n",
    "    # Make clean Year variable\n",
    "    pharmacies['Year'] = pharmacies.TRANSACTION_DATE\n",
    "    pharmacies = pharmacies[pharmacies.Year.isnull()==False] # Maryland had one transaction with null date\n",
    "    pharmacies.Year = pharmacies.Year.apply(str)\n",
    "    pharmacies.Year = pharmacies.Year.str.replace(r'\\.0$','') # Some files come in with decimal point in date\n",
    "    pharmacies.Year = pharmacies.Year.str.strip()\n",
    "    pharmacies.Year = pharmacies.Year.str[-4:]\n",
    "    pharmacies.Year = pharmacies.Year.astype(int)\n",
    "\n",
    "    # Calculate store counts and sales per store, by county, by year\n",
    "    per_store_by_county_by_year = pharmacies.groupby(by=['BUYER_DEA_NO','BUYER_NAME','BUYER_ADDRESS1','BUYER_CITY','BUYER_ZIP','BUYER_COUNTY','BUYER_STATE','Year']).DOSAGE_UNIT.sum().reset_index()\n",
    "    store_count_by_county_by_year = per_store_by_county_by_year.groupby(by=['BUYER_STATE','BUYER_COUNTY','Year']).BUYER_DEA_NO.count().reset_index()\n",
    "    store_count_by_county_by_year = store_count_by_county_by_year.rename(columns={'BUYER_DEA_NO':'Stores_in_county'})\n",
    "    per_store_by_county_by_year = pd.merge(per_store_by_county_by_year,store_count_by_county_by_year,on=['BUYER_STATE','BUYER_COUNTY','Year'],how='left')\n",
    "    average_store_count_by_county = store_count_by_county_by_year.groupby(by=['BUYER_STATE','BUYER_COUNTY']).Stores_in_county.mean().reset_index()\n",
    "    average_store_count_by_county = average_store_count_by_county.rename(columns={'Stores_in_county':'Average_stores_in_county'})\n",
    "\n",
    "    # Clean population info\n",
    "    population = pd.read_csv('county_pop_20062012.csv')\n",
    "    population.county_name = population.county_name.str.upper()\n",
    "    population = population[['BUYER_STATE','BUYER_COUNTY','pop2006','pop2007','pop2008','pop2009','pop2010','pop2011','pop2012']]\n",
    "    population = pd.melt(population,id_vars=['BUYER_STATE','BUYER_COUNTY'],var_name='Year', value_name='Population')\n",
    "    population.Year = population.Year.str.strip('pop')\n",
    "    population.Year = population.Year.astype(int)\n",
    "    per_store_by_county_by_year = pd.merge(per_store_by_county_by_year,population,on=['BUYER_STATE','BUYER_COUNTY','Year'],how='left')\n",
    "        \n",
    "    # Calculate pills per store share of county population in each year, then average across years at each store\n",
    "    per_store_by_county_by_year['One_year_rate'] = per_store_by_county_by_year.DOSAGE_UNIT.astype(float)/(per_store_by_county_by_year.Population/per_store_by_county_by_year.Stores_in_county)\n",
    "    per_store_alt = per_store_by_county_by_year.groupby(by=['BUYER_DEA_NO','BUYER_NAME','BUYER_ADDRESS1','BUYER_CITY','BUYER_ZIP','BUYER_COUNTY','BUYER_STATE']).One_year_rate.mean().reset_index()\n",
    "    per_store_alt = per_store_alt.rename(columns={'One_year_rate':'Alt_rate'})\n",
    "    per_store_alt = pd.merge(per_store_alt,average_store_count_by_county,on='BUYER_COUNTY',how='left')\n",
    "    per_store_alt.to_csv('all_stores_alternative_rate_'+state+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssuo1/OneDrive - Advance Local Media LLC/Code/opioids/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL\n",
      "AR\n",
      "AZ\n",
      "CO\n",
      "CT\n",
      "DE\n",
      "GA\n",
      "HI\n",
      "IA\n",
      "ID\n",
      "IL\n",
      "IN\n",
      "KS\n",
      "KY\n",
      "LA\n",
      "MA\n",
      "MD\n",
      "ME\n",
      "MI\n",
      "MN\n",
      "MO\n",
      "MS\n",
      "MT\n",
      "NC\n",
      "ND\n",
      "NE\n",
      "NH\n",
      "NJ\n",
      "NM\n",
      "NV\n",
      "NY\n",
      "OH\n",
      "OK\n",
      "OR\n",
      "PA\n",
      "RI\n",
      "SC\n",
      "SD\n",
      "TN\n",
      "UT\n",
      "VA\n",
      "VT\n",
      "WA\n",
      "WI\n",
      "WV\n",
      "WY\n",
      "TX\n",
      "CA\n",
      "FL\n"
     ]
    }
   ],
   "source": [
    "# Loop through the states. Unzip, process, and clear out one file at a time.\n",
    "# All data should go in a subdirectory called \"data\"\n",
    "# We will store the output in separate state csv's, concacatenating them afterward\n",
    "\n",
    "for state in states:\n",
    "    print state\n",
    "    zfile  = 'data/arcos-'+state.lower()+'-statewide-itemized.tsv.zip'\n",
    "    gzfile = 'data/arcos-'+state.lower()+'-statewide-itemized.tsv.gz'\n",
    "    try:\n",
    "        unzipped = 'data/' + state\n",
    "        zip = zipfile.ZipFile(zfile, 'r')\n",
    "        type = 'zip'\n",
    "        zip.extractall(unzipped)\n",
    "    except:\n",
    "        with gzip.open(gzfile, 'r') as f_in:\n",
    "            unzipped = 'data/arcos-'+state.lower()+'-statewide-itemized.tsv'\n",
    "            f_out = open(unzipped, 'w+') \n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "            f_in.close()\n",
    "        type = 'gzip'\n",
    "    process_one_state(state)\n",
    "    if type == 'zip':\n",
    "        shutil.rmtree(unzipped)\n",
    "    elif type == 'gzip':\n",
    "        os.remove(unzipped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make single file of many\n",
    "counties_full      = pd.DataFrame()\n",
    "counties_full_alt  = pd.DataFrame()\n",
    "for state in states:\n",
    "    thisfile = pd.read_csv('all_stores_' + state + '.csv')\n",
    "    counties_full = pd.concat([counties_full,thisfile])\n",
    "    thisfile = pd.read_csv('all_stores_alternative_rate_' + state + '.csv')\n",
    "    counties_full_alt = pd.concat([counties_full_alt,thisfile])\n",
    "\n",
    "counties_full.to_csv('all_stores.csv')\n",
    "counties_full_alt = counties_full_alt[['BUYER_DEA_NO','Alt_rate','Average_stores_in_county']]\n",
    "counties_full_alt.to_csv('all_stores_alt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Post results with alt results\n",
    "counties_full = pd.merge(counties_full,counties_full_alt,on='BUYER_DEA_NO',how='left')\n",
    "# Export output\n",
    "counties_full.to_csv('all_stores_combo.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
